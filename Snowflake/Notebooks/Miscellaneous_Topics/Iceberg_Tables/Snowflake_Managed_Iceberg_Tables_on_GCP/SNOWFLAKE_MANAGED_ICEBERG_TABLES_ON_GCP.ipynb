{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "vnlt4alne7foasgmiysz",
   "authorId": "3141283084560",
   "authorName": "PRAJAGOPAL",
   "authorEmail": "prasanna.rajagopal@snowflake.com",
   "sessionId": "16f8bf51-5464-459e-9ad6-1ded466d4065",
   "lastEditTime": 1746061427985
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1555b98f-f18b-4b86-9db5-29dd08bb46bc",
   "metadata": {
    "name": "MDTitleIcebergTables",
    "collapsed": false
   },
   "source": "# :snowflake: Snowflake-Managed :snowflake: Iceberg Tables\n## Creating & Managing Iceberg Tables on GCP\nAuthor: [Prasanna Rajagopal](https://www.linkedin.com/in/prasannarajagopal/)\n\nCreated: **April, 2025.** "
  },
  {
   "cell_type": "markdown",
   "id": "7f09190c-81a3-4394-bab9-4712bad38e8b",
   "metadata": {
    "name": "MDIcebergTableSteps",
    "collapsed": false
   },
   "source": "## Steps to Create Snowflake-Managed Iceberg Tables in GCP\n### 7 Easy Steps to Using [Apache Iceberg Tables in Snowflake](https://docs.snowflake.com/en/user-guide/tables-iceberg) \n#### - Create an IAM Role in GCP\n#### - Create a Bucket in [Google Cloud Storage (GCS)](https://cloud.google.com/storage?hl=en)\n#### - Create a [External Volume](https://docs.snowflake.com/en/user-guide/tables-iceberg#external-volume) in Snowflake pointing to the GCS Storage Bucket. \n#### - [Describe the External Volume](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-gcs#step-2-retrieve-the-gcs-service-account-for-your-snowflake-account) and Retrieve the GCP Service Account information for your Snowflake Account.\n#### - [Assign the Snowflake Service Account](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-gcs#assign-the-custom-role-to-the-gcs-service-account) as a Principal to the storage bucket and the role in GCP.\n#### - Test the External Volume to verify that the privileges on the storage bucket.  \n#### - Create Iceberg Tables."
  },
  {
   "cell_type": "markdown",
   "id": "d7cc3baf-5552-448e-b2c2-7ea67379ec44",
   "metadata": {
    "name": "MDIAMRoleGCP",
    "collapsed": false
   },
   "source": "## Create an IAM Role in GCP\n### The role should have the following minimum privileges.  \n```\nstorage.buckets.get\nstorage.objects.create\nstorage.objects.delete\nstorage.objects.get\nstorage.objects.list \n```"
  },
  {
   "cell_type": "markdown",
   "id": "0dfc684b-e036-416e-813b-5f8aeb5b2959",
   "metadata": {
    "name": "MDGCSBucket",
    "collapsed": false
   },
   "source": "## Create the GCS Bucket\n### Create the GCS bucket in the same region as your Snowflake account.  \n### Enable Encryption\n#### - Google-Managed Encryption Keys"
  },
  {
   "cell_type": "markdown",
   "id": "f44b0483-1047-437b-a57f-fb11b90311f8",
   "metadata": {
    "name": "MDCreateExternalVolume",
    "collapsed": false
   },
   "source": "## [Create the Snowflake External Volume](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume)\n- An external volume is a named, account-level Snowflake object that you use to connect Snowflake to your external cloud storage for Iceberg tables. \n- An external volume stores an identity and access management (IAM) entity for your storage location. \n- Snowflake uses the IAM entity to securely connect to your storage for accessing table data, Iceberg metadata, and manifest files that store the table schema, partitions, and other metadata."
  },
  {
   "cell_type": "code",
   "id": "bae622c5-3a43-4a01-a88c-dab7b08317d9",
   "metadata": {
    "language": "sql",
    "name": "SQLCreateExternalVol"
   },
   "outputs": [],
   "source": "CREATE EXTERNAL VOLUME iceberg_test_ext_vol\n  STORAGE_LOCATIONS =\n    (\n      (\n        NAME = 'ext_us_east4'\n        STORAGE_PROVIDER = 'GCS'\n        STORAGE_BASE_URL = 'gcs://newgcpsnowbucket1/'\n      )\n    );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "440fbead-feb0-4ace-b83c-4b737dcee97d",
   "metadata": {
    "name": "MDDescExtVol",
    "collapsed": false
   },
   "source": "## [Retrieve The GCS Service Account For Your Snowflake Account](https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-gcs#step-2-retrieve-the-gcs-service-account-for-your-snowflake-account)\n## Describe the Snowflake External Volume\n### Output from the describe command\n```JSON\n{\n\"NAME\":\"ext_us_east4\",\n\"STORAGE_PROVIDER\":\"GCS\",\n\"STORAGE_BASE_URL\":\"gcs://newgcpsnowbucket1/\",\n\"STORAGE_ALLOWED_LOCATIONS\":[\"gcs://newgcpsnowbucket1/*\"],\n\"STORAGE_REGION\":\"US-EAST4\",\n\"PRIVILEGES_VERIFIED\":true,\n\"STORAGE_GCP_SERVICE_ACCOUNT\":\"service-account-id@project1-123456.iam.gserviceaccount.com\",\n\"ENCRYPTION_TYPE\":\"NONE\",\"ENCRYPTION_KMS_KEY_ID\":\"\"\n}\n```\n#### Record the value of the STORAGE_GCP_SERVICE_ACCOUNT property in the output (for example, service-account-id@project1-123456.iam.gserviceaccount.com).\n#### Snowflake provisions a single GCS service account for your entire Snowflake account. All GCS external volumes use that service account.\n#### Filter the list of buckets, and select the bucket that you specified when you created an external volume.\n#### Select Permissions Â» View by principals, then select Grant access.\n#### Under Add principals, paste the name of the service account name from the output in the DESC EXTERNAL VOLUME command.  \n#### Under Assign roles, select the custom IAM role that you created previously, then select Save.\n\n\n"
  },
  {
   "cell_type": "code",
   "id": "7aa04ddc-d03d-4095-9ea2-d31266137ce7",
   "metadata": {
    "language": "sql",
    "name": "SQLDescExtVol"
   },
   "outputs": [],
   "source": "DESC EXTERNAL VOLUME iceberg_test_ext_vol;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8ef9d6ff-e9d0-4e00-b09c-6f663b91eecb",
   "metadata": {
    "name": "MDVerifyExternalVolume",
    "collapsed": false
   },
   "source": "## Test the External Volume\n- Verifies the configuration for a specified external volume.\n\nFor external volumes with write access, Snowflake attempts the following additional operations to verify the configuration:\n\n- Write a test file.\n\n- Read the test file.\n\n- List the files in the storage location.\n\n- Delete the test file.\n```SQL\nSELECT SYSTEM$VERIFY_EXTERNAL_VOLUME('iceberg_test_ext_vol');\n```"
  },
  {
   "cell_type": "markdown",
   "id": "c89b6c05-d36e-42b4-a630-b2c46f11fd19",
   "metadata": {
    "name": "MDCreateIcebergTable",
    "collapsed": false
   },
   "source": "## Create the Iceberg Table in Snowflake"
  },
  {
   "cell_type": "code",
   "id": "1438e394-619d-4474-9210-c53e07ebc1c9",
   "metadata": {
    "language": "sql",
    "name": "CreateIcebergTable"
   },
   "outputs": [],
   "source": "CREATE ICEBERG TABLE equity_info_itbl (SYMBOL VARCHAR, COMPANY_NAME VARCHAR)\n    CATALOG = 'SNOWFLAKE'\n   EXTERNAL_VOLUME='iceberg_test_ext_vol'\n   METADATA_FILE_PATH='metadata/v1.metadata.json';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "daa21850-0599-4af8-9537-7aff7a72550c",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "CREATE ICEBERG TABLE equity_info_itbl2 (SYMBOL VARCHAR, COMPANY_NAME VARCHAR)\n    CATALOG = 'SNOWFLAKE'\n   EXTERNAL_VOLUME='iceberg_test_ext_vol'\n   BASE_LOCATION = 'equity_info_itbl2'\n   METADATA_FILE_PATH='metadata/v1.metadata.json';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f8fce3f-f322-415c-855a-a33e81973b8a",
   "metadata": {
    "language": "sql",
    "name": "SQLCreateIcebergTable"
   },
   "outputs": [],
   "source": "-- Just the Metadata Directory, no initial file name.  \nCREATE ICEBERG TABLE equity_prices_itbl (SYMBOL VARCHAR, COMPANY_NAME VARCHAR)\n    CATALOG = 'SNOWFLAKE'\n   EXTERNAL_VOLUME='iceberg_test_ext_vol'\n   METADATA_FILE_PATH='metadata/'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "540f9d78-9eb6-4770-beae-10fab0210133",
   "metadata": {
    "language": "sql",
    "name": "SQLDescIcebergTable"
   },
   "outputs": [],
   "source": "DESC TABLE equity_info_itbl;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99204ed0-f522-410b-bef8-138a1458f3dd",
   "metadata": {
    "language": "sql",
    "name": "SQLShowTables"
   },
   "outputs": [],
   "source": "SHOW TABLES LIKE 'equity_info_itbl';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a64055f-8447-4a0e-ad55-f22f563ff2df",
   "metadata": {
    "language": "sql",
    "name": "SQLInsertIntoIcebergTable"
   },
   "outputs": [],
   "source": "INSERT INTO equity_info_itbl VALUES ('AAPL', 'APPLE Inc.');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7af8a15a-0af5-4dce-a86f-8375dae0a336",
   "metadata": {
    "language": "sql",
    "name": "SQLSelectFromIcebergTable"
   },
   "outputs": [],
   "source": "SELECT * FROM equity_info_itbl;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "432f3144-8759-425a-a1b1-1f39da0420ba",
   "metadata": {
    "language": "sql",
    "name": "SQLInsertWMT"
   },
   "outputs": [],
   "source": "INSERT INTO equity_info_itbl VALUES ('WMT', 'Walmart Inc.');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e35883e1-a784-49a9-97b8-d33252074bf4",
   "metadata": {
    "language": "sql",
    "name": "SQLInsertTGT"
   },
   "outputs": [],
   "source": "INSERT INTO equity_info_itbl VALUES ('TGT', 'TARGET CORPORATION');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2153945f-441a-4f40-a1eb-e951006110f2",
   "metadata": {
    "name": "MDLoad_Parquet_Files_Into_Iceberg_Tables",
    "collapsed": false
   },
   "source": "## Load Data Received in PARQUET File into Iceberg Table Managed by Snowflake\n### Step 1: Create a File Format\n### Step 2: Use COPY INTO <TABLE> Statement\n### Step 3: Create a Task with the COPY Statement (Step 2) to Ingest PARQUET files on a Schedule.  "
  },
  {
   "cell_type": "markdown",
   "id": "7770226b-b2b6-475f-8f5d-ef8cfc2bdbca",
   "metadata": {
    "name": "MDCreate_File_Format",
    "collapsed": false
   },
   "source": "## Create a File Format"
  },
  {
   "cell_type": "code",
   "id": "1f84d144-cd3f-4b6c-bd14-8e14d0feb70b",
   "metadata": {
    "language": "sql",
    "name": "SQLCreate_Parquet_File_Format"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FILE FORMAT my_parquet_file_format\n  TYPE = PARQUET\n  USE_VECTORIZED_SCANNER = TRUE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d599036c-a82f-4bec-86a7-2f756d3c9384",
   "metadata": {
    "name": "MDCOPY_INTO_ICEBERG_TABLE",
    "collapsed": false
   },
   "source": "## [COPY INTO <TABLE>](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table)\n```SQL \nCOPY INTO customer_iceberg_ingest\n  FROM @DEMODB.EQUITY_RESEARCH.PARQUET_FILES_INT_STG\n  FILE_FORMAT = 'my_parquet_file_format'\n  LOAD_MODE = ADD_FILES_COPY\n  PURGE = TRUE\n  MATCH_BY_COLUMN_NAME = CASE_SENSITIVE;\n```\n\n```LOAD_MODE = ADD_FILES_COPY```\n- This is a critical part for Iceberg tables. \n- It determines how the data is loaded into the Iceberg table. \n- Two ```LOAD_MODE``` Options\n    - ```ADD_FILES_COPY```\n    - ```FULL_INGEST```\n- ```ADD_FILES_COPY``` \n    - Snowflake performs a server-side copy of the original Parquet files into the base location of the Iceberg table. \n    - It then registers the files to the table. \n    - This allows for cross-region or cross-cloud ingestion of raw Parquet files into Iceberg tables.\n    - Mode adds the files to the Iceberg metadata without rewriting the data files. \n    - This is generally faster than other modes.\n    - This mode potentially reduces data ingestion costs and time. \n- ```FULL_INGEST``` \n    - Snowflake scans the files and rewrites the Parquet data under the base location of the Iceberg table. \n    - Use this option if you need to transform or convert the data before registering the files to your Iceberg table.\n\n```PURGE = TRUE```\n- This option tells Snowflake to delete the files from the stage after they have been successfully loaded into the table.\n\n```MATCH_BY_COLUMN_NAME = CASE_SENSITIVE```\n- This option specifies how the columns in the data files are matched to the columns in the target table. \n\n```CASE_SENSITIVE``` \n- Means that the column names must match exactly, including the case."
  },
  {
   "cell_type": "code",
   "id": "bdd51558-cccf-4360-af2e-13c4d398c4a5",
   "metadata": {
    "language": "sql",
    "name": "SQLCOPY_PARQUET_INTO_ICEBERG_TABLE"
   },
   "outputs": [],
   "source": "COPY INTO demodb.test.customer_iceberg_ingest_gcp\n  FROM @PARQUET_FILES_INT_STG\n  FILE_FORMAT = 'my_parquet_file_format'\n  LOAD_MODE = ADD_FILES_COPY\n  PURGE = TRUE\n  MATCH_BY_COLUMN_NAME = CASE_SENSITIVE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "534c719d-e216-4832-92bc-ce0e36c44602",
   "metadata": {
    "name": "MDCreate_Task_With_COPY_Command",
    "collapsed": false
   },
   "source": "## Create a Task With the COPY Command.\n```SQL\nCREATE OR REPLACE TASK customer_iceberg_ingest_task\n  SCHEDULE = '1 MINUTES'\n  WAREHOUSE = 'COMPUTE_WH'\n  AS\n    COPY INTO customer_iceberg_ingest\n      FROM @DEMODB.EQUITY_RESEARCH.PARQUET_FILES_INT_STG\n      FILE_FORMAT = 'my_parquet_file_format'\n      LOAD_MODE = ADD_FILES_COPY\n      PURGE = TRUE\n      MATCH_BY_COLUMN_NAME = CASE_SENSITIVE;\n```\n"
  },
  {
   "cell_type": "code",
   "id": "d394b85e-ebf2-416c-bc58-1147780c50e5",
   "metadata": {
    "language": "sql",
    "name": "SQLCreate_Task_COPY_Command"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TASK customer_iceberg_ingest_task\n  SCHEDULE = '1 MINUTES'\n  WAREHOUSE = 'COMPUTE_WH'\n  AS\n    COPY INTO customer_iceberg_ingest\n      FROM @DEMODB.EQUITY_RESEARCH.PARQUET_FILES_INT_STG\n      FILE_FORMAT = 'my_parquet_file_format'\n      LOAD_MODE = ADD_FILES_COPY\n      PURGE = TRUE\n      MATCH_BY_COLUMN_NAME = CASE_SENSITIVE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e32c1ef9-22f9-4599-a3e7-53e9cfbcba7a",
   "metadata": {
    "name": "MDIcebergTableInformation",
    "collapsed": false
   },
   "source": "## SYSTEM$GET_ICEBERG_TABLE_INFORMATION\n- Returns the location of the root metadata file and status of the latest snapshot for an Apache Iceberg table.\n\nThe SYSTEM$GET_ICEBERG_TABLE_INFORMATION function works differently according to table type:\n\n- For an Iceberg table that uses Snowflake as the catalog, calling the function generates metadata for data manipulation language (DML) operations or other table updates that have occurred since Snowflake last generated metadata for the table.\n\n- If there are no updates, the function returns the location of the latest metadata file, but does not generate new metadata.\n\n- For an Iceberg table that is not managed by Snowflake, the function returns information about the latest refreshed snapshot.\n\n"
  },
  {
   "cell_type": "code",
   "id": "9e92328d-91b8-4be6-b492-486aef1998f3",
   "metadata": {
    "language": "sql",
    "name": "SQLIcebergTableInformation"
   },
   "outputs": [],
   "source": "SELECT SYSTEM$GET_ICEBERG_TABLE_INFORMATION('DEMODB.EQUITY_RESEARCH.equity_info_itbl');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc60ee89-2719-42e3-9623-42e6c187aa7b",
   "metadata": {
    "name": "MDRefreshIcebergTable",
    "collapsed": false
   },
   "source": "### Refresh of Iceberg table Only Works for Externally-managed Iceberg Tables"
  },
  {
   "cell_type": "code",
   "id": "369863c0-b682-4600-8745-e253921f9178",
   "metadata": {
    "language": "sql",
    "name": "SQLRefreshIcebergTable"
   },
   "outputs": [],
   "source": "ALTER ICEBERG TABLE DEMODB.EQUITY_RESEARCH.equity_info_itbl REFRESH;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee885013-8011-4bba-8482-a3ddb3b0034e",
   "metadata": {
    "name": "MDRowLevelDeletes",
    "collapsed": false
   },
   "source": "## [Use Row-level Deletes](https://docs.snowflake.com/en/user-guide/tables-iceberg-manage#use-row-level-deletes)\n- Iceberg provides two modes for configuring how compute engines handle row-level operations for externally managed tables. \n- Snowflake supports both of these modes.\n### [Copy-on-write vs. merge-on-read](https://docs.snowflake.com/en/user-guide/tables-iceberg-manage#copy-on-write-vs-merge-on-read)\n#### Copy-on-write\n- **Copy-on-write is the default** in Snowflake\n- This mode prioritizes read time and impacts write speed.\n- When you perform an update, delete, or merge operation, your **compute engine rewrites the entire affected Parquet data file**. \n- This can result in **slow writes**, especially if you have **large data files**, but **doesnât impact read time**.\n#### Merge-on-read\n- This mode **prioritizes write speed** and **slightly impacts read time**.\n- When you perform an update, delete, or merge operation, your **compute engine creates a delete file that contains information about only the changed rows**.\n- When you read from a table, your query engine merges delete files with data files. Merging can increase read time. \n- However, you can optimize read performance by scheduling regular compaction and table maintenance."
  },
  {
   "cell_type": "code",
   "id": "3d39542c-d239-4c10-9993-e2c8bd358d67",
   "metadata": {
    "language": "sql",
    "name": "SQLDeleteWMT"
   },
   "outputs": [],
   "source": "DELETE FROM equity_info_itbl WHERE SYMBOL = 'WMT'",
   "execution_count": null
  }
 ]
}